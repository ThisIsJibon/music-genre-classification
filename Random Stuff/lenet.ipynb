{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93d1be34",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layer_utils\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpydot\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVG\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvis_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model_to_dot\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pydot'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from pydub import AudioSegment\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.utils import get_file\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import SVG\n",
    "\n",
    "# Mount your Google Drive if you want to access files from there in Jupyter Notebook\n",
    "# Replace this with your actual path\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "# Define the list of genres\n",
    "genres = [\n",
    "    \"Adhunik\", \"Folk\", \"Hiphop\", \"Indie\", \n",
    "    \"Islamic\", \"Metal\", \"Pop\", \"Rock\"\n",
    "    ]\n",
    "genres = genres.split()\n",
    "\n",
    "# Define paths for audio and spectrogram folders\n",
    "for g in genres:\n",
    "    path1 = os.path.join('audio3sec', f'{g}')\n",
    "    os.makedirs(path1)\n",
    "    path = os.path.join('spectrograms3sec', f'{g}')\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Define path for spectrogram directory\n",
    "os.makedirs('spectrograms3sec')\n",
    "\n",
    "\n",
    "# Loop through genres and audio files, create spectrograms\n",
    "for g in genres:\n",
    "    j = 0\n",
    "    print(g)\n",
    "    for filename in os.listdir(os.path.join('audio3sec', f\"{g}\")):\n",
    "        song = os.path.join(f'audio3sec/{g}', f'{filename}')\n",
    "        j = j + 1\n",
    "        y, sr = librosa.load(song, duration=3)\n",
    "        mels = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        p = librosa.display.specshow(librosa.power_to_db(mels, ref=np.max))\n",
    "        z = librosa.power_to_db(mels, ref=np.max)\n",
    "        plt.imsave(f'spectrograms3sec/{g}/{g+str(j)}.png', z)\n",
    "\n",
    "# Move files to train and test directories\n",
    "directory = \"spectrograms3sec/train/\"\n",
    "for g in genres:\n",
    "    filenames = os.listdir(os.path.join(directory, f\"{g}\"))\n",
    "    random.shuffle(filenames)\n",
    "    test_files = filenames[0:100]\n",
    "    \n",
    "    for f in test_files:\n",
    "        shutil.move(directory + f\"{g}\" + \"/\" + f, \"spectrograms3sec/test/\" + f\"{g}\")\n",
    "\n",
    "# Define the model architecture\n",
    "def GenreModel(input_shape=(288, 432, 4), classes=9):\n",
    "    np.random.seed(9)\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = Conv2D(8, kernel_size=(3, 3), strides=(1, 1), kernel_initializer=glorot_uniform(seed=9))(X_input)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2))(X)\n",
    "\n",
    "    # Add more layers following the same pattern\n",
    "    # ...\n",
    "\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer=glorot_uniform(seed=9))(X)\n",
    "\n",
    "    model = Model(inputs=X_input, outputs=X, name='GenreModel')\n",
    "    return model\n",
    "\n",
    "# Compile and train the model\n",
    "model = GenreModel(input_shape=(288, 432, 4), classes=9)\n",
    "opt = Adam(learning_rate=0.00005)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy', get_f1])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Define train and validation data generators\n",
    "train_dir = \"spectrograms3sec/train/\"\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(288, 432), color_mode=\"rgba\", class_mode='categorical', batch_size=128)\n",
    "\n",
    "validation_dir = \"spectrograms3sec/test/\"\n",
    "vali_datagen = ImageDataGenerator(rescale=1./255)\n",
    "vali_generator = vali_datagen.flow_from_directory(validation_dir, target_size=(288, 432), color_mode='rgba', class_mode='categorical', batch_size=128)\n",
    "\n",
    "# Train the model\n",
    "model.fit_generator(train_generator, epochs=40, validation_data=vali_generator)\n",
    "\n",
    "# Evaluate the model\n",
    "preds = model.evaluate(x=X_test, y=Y_test)\n",
    "print(preds[1])\n",
    "print(preds[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e46b46fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: keras\n",
      "Version: 2.12.0\n",
      "Summary: Deep learning for humans.\n",
      "Home-page: https://keras.io/\n",
      "Author: Keras team\n",
      "Author-email: keras-users@googlegroups.com\n",
      "License: Apache 2.0\n",
      "Location: c:\\users\\asus\\anaconda3\\lib\\site-packages\n",
      "Requires: \n",
      "Required-by: tensorflow-intel\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06debd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef7f304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "i = 0\n",
    "for g in genres:\n",
    "  j=0\n",
    "  print(f\"{g}\")\n",
    "  for filename in os.listdir(os.path.join('/content/drive/My Drive/Bangla Music Data/',f\"{g}\")):\n",
    "\n",
    "    song  =  os.path.join(f'/content/drive/My Drive/Bangla Music Data/{g}',f'{filename}')\n",
    "    j = j+1\n",
    "    for w in range(0,10):\n",
    "      i = i+1\n",
    "      #print(i)\n",
    "      t1 = 3*(w)*1000\n",
    "      t2 = 3*(w+1)*1000\n",
    "      newAudio = AudioSegment.from_wav(song)\n",
    "      new = newAudio[t1:t2]\n",
    "      new.export(f'/content/audio3sec/{g}/{g+str(j)+str(w)}.wav', format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a266a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in genres:\n",
    "  j = 0\n",
    "  print(g)\n",
    "  for filename in os.listdir(os.path.join('/content/audio3sec',f\"{g}\")):\n",
    "    song  =  os.path.join(f'/content/audio3sec/{g}',f'{filename}')\n",
    "    j = j+1\n",
    "\n",
    "    y,sr = librosa.load(song,duration=3)\n",
    "    #print(sr)\n",
    "    mels = librosa.feature.melspectrogram(y=y,sr=sr)\n",
    "    fig = plt.Figure()\n",
    "    canvas = FigureCanvas(fig)\n",
    "    p = plt.imshow(librosa.power_to_db(mels,ref=np.max))\n",
    "    plt.savefig(f'/content/drive/My Drive/Bangla Music Data/train/{g}/{g+str(j)}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a3498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/content/drive/My Drive/gtzan/train/\"\n",
    "for g in genres:\n",
    "\n",
    "  filenames = os.listdir(os.path.join(directory,f\"{g}\"))\n",
    "\n",
    "  random.shuffle(filenames)\n",
    "  test_files = filenames[0:70]\n",
    "\n",
    "  for f in test_files:\n",
    "\n",
    "    shutil.move(directory + f\"{g}\"+ \"/\" + f,\"/content/drive/My Drive/gtzan/test/\" + f\"{g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd60737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/content/drive/My Drive/gtzan/train/\"\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,target_size=(288,432),color_mode=\"rgba\",class_mode='categorical',batch_size=128)\n",
    "\n",
    "validation_dir = \"/content/drive/My Drive/gtzan/test/\"\n",
    "vali_datagen = ImageDataGenerator(rescale=1./255)\n",
    "vali_generator = vali_datagen.flow_from_directory(validation_dir,target_size=(288,432),color_mode='rgba',class_mode='categorical',batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd959b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenreModel(input_shape = (288,432,4),classes=9):\n",
    "\n",
    "  X_input = Input(input_shape)\n",
    "\n",
    "  X = Conv2D(8,kernel_size=(3,3),strides=(1,1))(X_input)\n",
    "  X = BatchNormalization(axis=3)(X)\n",
    "  X = Activation('relu')(X)\n",
    "  X = MaxPooling2D((2,2))(X)\n",
    "\n",
    "  X = Conv2D(16,kernel_size=(3,3),strides = (1,1))(X)\n",
    "  X = BatchNormalization(axis=3)(X)\n",
    "  X = Activation('relu')(X)\n",
    "  X = MaxPooling2D((2,2))(X)\n",
    "\n",
    "  X = Conv2D(32,kernel_size=(3,3),strides = (1,1))(X)\n",
    "  X = BatchNormalization(axis=3)(X)\n",
    "  X = Activation('relu')(X)\n",
    "  X = MaxPooling2D((2,2))(X)\n",
    "\n",
    "  X = Conv2D(64,kernel_size=(3,3),strides=(1,1))(X)\n",
    "  X = BatchNormalization(axis=-1)(X)\n",
    "  X = Activation('relu')(X)\n",
    "  X = MaxPooling2D((2,2))(X)\n",
    "\n",
    "  X = Conv2D(128,kernel_size=(3,3),strides=(1,1))(X)\n",
    "  X = BatchNormalization(axis=-1)(X)\n",
    "  X = Activation('relu')(X)\n",
    "  X = MaxPooling2D((2,2))(X)\n",
    "\n",
    "\n",
    "  X = Flatten()(X)\n",
    "\n",
    "  X = Dropout(rate=0.3)(X)\n",
    "\n",
    "  X = Dense(classes, activation='softmax', name='fc' + str(classes))(X)\n",
    "\n",
    "  model = Model(inputs=X_input,outputs=X,name='GenreModel')\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187c8fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GenreModel(input_shape=(288,432,4),classes=7)\n",
    "opt = Adam(learning_rate=0.0005)\n",
    "model.compile(optimizer = opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_generator,epochs=70,validation_data=vali_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62297312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenet(input_shape = (288,432,4),classes=9):\n",
    "\n",
    "  X_input = Input(input_shape)\n",
    "  X = Conv2D(8, (3,3), activation='relu')(X_input)\n",
    "  X = AveragePooling2D()(X)\n",
    "  X = Dropout(0.2)(X)\n",
    "  X = Conv2D(16, (3,3), activation='relu')(X)\n",
    "  X = AveragePooling2D()(X)\n",
    "  X = Dropout(0.2)(X)\n",
    "  X = Flatten()(X)\n",
    "\n",
    "  X = Dense(120, activation='relu')(X)\n",
    "  X = Dropout(0.3)(X)\n",
    "  X = Dense(84, activation='relu')(X)\n",
    "  X = Dropout(0.4)(X)\n",
    "  X = Dense(7, activation = 'softmax')(X)\n",
    "\n",
    "\n",
    "  model = Model(inputs=X_input,outputs=X,name='lenetModel')\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0048833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = lenet(input_shape=(288,432,4),classes=7)\n",
    "opt = Adam(learning_rate=0.0005)\n",
    "model1.compile(optimizer = opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model1.fit(train_generator,epochs=20,validation_data=vali_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
