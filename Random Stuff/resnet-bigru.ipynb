{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69b6736d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6168 images belonging to 8 classes.\n",
      "Found 1541 images belonging to 8 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'sub_34' defined at (most recent call last):\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_12808\\3423737063.py\", line 94, in <module>\n      history = combined_model.fit(\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1054, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer.py\", line 543, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer.py\", line 1174, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer.py\", line 650, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer.py\", line 1200, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer.py\", line 1250, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer.py\", line 1247, in apply_grad_to_update_var\n      return self._update_step(grad, var)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer.py\", line 240, in _update_step\n      self.update_step(gradient, variable)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\optimizers\\adam.py\", line 194, in update_step\n      m.assign_add((gradient - m) * (1 - self.beta_1))\nNode: 'sub_34'\nOOM when allocating tensor with shape[1967680,256] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node sub_34}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_30273]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 94\u001b[0m\n\u001b[0;32m     87\u001b[0m combined_model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     88\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m),\n\u001b[0;32m     89\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     90\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     91\u001b[0m )\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mcombined_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Evaluate the model on test data\u001b[39;00m\n\u001b[0;32m    102\u001b[0m test_generator \u001b[38;5;241m=\u001b[39m datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m    103\u001b[0m     data_dir,\n\u001b[0;32m    104\u001b[0m     target_size\u001b[38;5;241m=\u001b[39minput_shape[:\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m     subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# You can change this to 'test' if you have a separate test folder\u001b[39;00m\n\u001b[0;32m    108\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'sub_34' defined at (most recent call last):\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_12808\\3423737063.py\", line 94, in <module>\n      history = combined_model.fit(\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1054, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer.py\", line 543, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer.py\", line 1174, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer.py\", line 650, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer.py\", line 1200, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer.py\", line 1250, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer.py\", line 1247, in apply_grad_to_update_var\n      return self._update_step(grad, var)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer.py\", line 240, in _update_step\n      self.update_step(gradient, variable)\n    File \"C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\optimizers\\adam.py\", line 194, in update_step\n      m.assign_add((gradient - m) * (1 - self.beta_1))\nNode: 'sub_34'\nOOM when allocating tensor with shape[1967680,256] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node sub_34}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_30273]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Bidirectional, GRU, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Constants\n",
    "data_dir = r\"E:\\Research\\ML - Machine Learning\\Music Genre Classification\\Data\\spectrogram_from_mahin\"  # Path to your dataset containing subfolders for each genre\n",
    "input_shape = (288, 432, 3)  # Adjust the input shape based on your spectrogram size\n",
    "batch_size = 16\n",
    "epochs = 30\n",
    "\n",
    "# Data Preprocessing using ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,  # Normalize pixel values\n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Define the ResNet model\n",
    "def build_resnet(input_shape, num_classes):\n",
    "    base_model = tf.keras.applications.ResNet50(\n",
    "        include_top=False, weights='imagenet', input_shape=input_shape\n",
    "    )\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Define the Bi-GRU model\n",
    "def build_bigru(input_shape, num_classes):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(input_layer)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    # Reshape the features to include a time dimension\n",
    "    x = tf.keras.layers.Reshape((1, -1))(x)\n",
    "    x = Bidirectional(GRU(128))(x)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Build the combined model\n",
    "num_classes = len(train_generator.class_indices)\n",
    "resnet_model = build_resnet(input_shape, num_classes)\n",
    "bigru_model = build_bigru(input_shape, num_classes)\n",
    "\n",
    "combined_input = Input(shape=input_shape)\n",
    "resnet_features = resnet_model(combined_input)\n",
    "bigru_features = bigru_model(combined_input)\n",
    "combined_features = tf.keras.layers.Concatenate(axis=-1)([resnet_features, bigru_features])\n",
    "output = Dense(num_classes, activation='softmax')(combined_features)\n",
    "combined_model = Model(inputs=combined_input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "combined_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = combined_model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',  # You can change this to 'test' if you have a separate test folder\n",
    ")\n",
    "\n",
    "y_true = test_generator.classes\n",
    "y_pred = combined_model.predict(test_generator)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Classification report and accuracy\n",
    "classification_rep = classification_report(y_true, y_pred_labels, target_names=train_generator.class_indices.keys())\n",
    "accuracy = accuracy_score(y_true, y_pred_labels)\n",
    "\n",
    "# Plot the training history\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print classification report and accuracy\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce56aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
