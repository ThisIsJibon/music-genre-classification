{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5db85f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gi\n"
     ]
    }
   ],
   "source": [
    "def preprocess(dataset_path, num_mfcc=40, n_fft=2048, hop_length =512, num_segment=10):\n",
    "    data = {\"labels\": [], \"mfcc\":[]}\n",
    "    sample_rate = 22050\n",
    "    samples_per_segment = int(sample_rate*30/num_segment)\n",
    "    \n",
    "    for label_idx, (dirpath, dirnames, filenames) in enumerate (os.walk(dataset_path)):\n",
    "        if dirpath == dataset_path:\n",
    "            continue\n",
    "        for f in sorted(filenames):\n",
    "            if not f.endswith('.wav'):\n",
    "                continue\n",
    "            file_path = str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0cc2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 38, 32)       320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 19, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 62, 17, 128)       36992     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 31, 8, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 31, 8, 128)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 29, 6, 128)        147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 29, 6, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 29, 6, 128)        0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               66048     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 4104      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 255,048\n",
      "Trainable params: 255,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.3296 - accuracy: 0.3587\n",
      "Epoch 1: val_accuracy improved from -inf to 0.52020, saving model to best_model.hdf5\n",
      "304/304 [==============================] - 66s 211ms/step - loss: 0.3296 - accuracy: 0.3588 - val_loss: 0.2681 - val_accuracy: 0.5202\n",
      "Epoch 2/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.2537 - accuracy: 0.5369\n",
      "Epoch 2: val_accuracy improved from 0.52020 to 0.57255, saving model to best_model.hdf5\n",
      "304/304 [==============================] - 77s 255ms/step - loss: 0.2537 - accuracy: 0.5371 - val_loss: 0.2275 - val_accuracy: 0.5725\n",
      "Epoch 3/400\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.2325 - accuracy: 0.5793\n",
      "Epoch 3: val_accuracy improved from 0.57255 to 0.60058, saving model to best_model.hdf5\n",
      "304/304 [==============================] - 73s 241ms/step - loss: 0.2325 - accuracy: 0.5793 - val_loss: 0.2221 - val_accuracy: 0.6006\n",
      "Epoch 4/400\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.2204 - accuracy: 0.6060\n",
      "Epoch 4: val_accuracy improved from 0.60058 to 0.64963, saving model to best_model.hdf5\n",
      "304/304 [==============================] - 73s 242ms/step - loss: 0.2204 - accuracy: 0.6060 - val_loss: 0.2075 - val_accuracy: 0.6496\n",
      "Epoch 5/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.2149 - accuracy: 0.6109\n",
      "Epoch 5: val_accuracy did not improve from 0.64963\n",
      "304/304 [==============================] - 73s 241ms/step - loss: 0.2150 - accuracy: 0.6108 - val_loss: 0.2026 - val_accuracy: 0.6492\n",
      "Epoch 6/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.2080 - accuracy: 0.6276\n",
      "Epoch 6: val_accuracy improved from 0.64963 to 0.65087, saving model to best_model.hdf5\n",
      "304/304 [==============================] - 68s 223ms/step - loss: 0.2080 - accuracy: 0.6276 - val_loss: 0.1998 - val_accuracy: 0.6509\n",
      "Epoch 7/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.2027 - accuracy: 0.6367\n",
      "Epoch 7: val_accuracy improved from 0.65087 to 0.65540, saving model to best_model.hdf5\n",
      "304/304 [==============================] - 67s 221ms/step - loss: 0.2026 - accuracy: 0.6367 - val_loss: 0.1917 - val_accuracy: 0.6554\n",
      "Epoch 8/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1992 - accuracy: 0.6421\n",
      "Epoch 8: val_accuracy improved from 0.65540 to 0.66241, saving model to best_model.hdf5\n",
      "304/304 [==============================] - 77s 253ms/step - loss: 0.1992 - accuracy: 0.6420 - val_loss: 0.1939 - val_accuracy: 0.6624\n",
      "Epoch 9/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1957 - accuracy: 0.6498\n",
      "Epoch 9: val_accuracy improved from 0.66241 to 0.68137, saving model to best_model.hdf5\n",
      "304/304 [==============================] - 71s 232ms/step - loss: 0.1958 - accuracy: 0.6496 - val_loss: 0.1861 - val_accuracy: 0.6814\n",
      "Epoch 10/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1928 - accuracy: 0.6528\n",
      "Epoch 10: val_accuracy improved from 0.68137 to 0.68714, saving model to best_model.hdf5\n",
      "304/304 [==============================] - 69s 228ms/step - loss: 0.1928 - accuracy: 0.6529 - val_loss: 0.1813 - val_accuracy: 0.6871\n",
      "Epoch 11/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1870 - accuracy: 0.6695\n",
      "Epoch 11: val_accuracy did not improve from 0.68714\n",
      "304/304 [==============================] - 71s 234ms/step - loss: 0.1870 - accuracy: 0.6694 - val_loss: 0.1802 - val_accuracy: 0.6855\n",
      "Epoch 12/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1839 - accuracy: 0.6753\n",
      "Epoch 12: val_accuracy improved from 0.68714 to 0.70074, saving model to best_model.hdf5\n",
      "304/304 [==============================] - 70s 231ms/step - loss: 0.1839 - accuracy: 0.6753 - val_loss: 0.1751 - val_accuracy: 0.7007\n",
      "Epoch 13/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1830 - accuracy: 0.6765\n",
      "Epoch 13: val_accuracy did not improve from 0.70074\n",
      "304/304 [==============================] - 71s 232ms/step - loss: 0.1831 - accuracy: 0.6765 - val_loss: 0.1776 - val_accuracy: 0.6863\n",
      "Epoch 14/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1800 - accuracy: 0.6797\n",
      "Epoch 14: val_accuracy did not improve from 0.70074\n",
      "304/304 [==============================] - 69s 228ms/step - loss: 0.1800 - accuracy: 0.6796 - val_loss: 0.1757 - val_accuracy: 0.6814\n",
      "Epoch 15/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1781 - accuracy: 0.6877\n",
      "Epoch 15: val_accuracy improved from 0.70074 to 0.70239, saving model to best_model.hdf5\n",
      "304/304 [==============================] - 70s 229ms/step - loss: 0.1781 - accuracy: 0.6877 - val_loss: 0.1722 - val_accuracy: 0.7024\n",
      "Epoch 16/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1749 - accuracy: 0.6946\n",
      "Epoch 16: val_accuracy improved from 0.70239 to 0.70940, saving model to best_model.hdf5\n",
      "304/304 [==============================] - 74s 243ms/step - loss: 0.1749 - accuracy: 0.6947 - val_loss: 0.1695 - val_accuracy: 0.7094\n",
      "Epoch 17/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1726 - accuracy: 0.6945\n",
      "Epoch 17: val_accuracy did not improve from 0.70940\n",
      "304/304 [==============================] - 78s 257ms/step - loss: 0.1727 - accuracy: 0.6945 - val_loss: 0.1702 - val_accuracy: 0.7032\n",
      "Epoch 18/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1709 - accuracy: 0.6997\n",
      "Epoch 18: val_accuracy did not improve from 0.70940\n",
      "304/304 [==============================] - 71s 232ms/step - loss: 0.1708 - accuracy: 0.6998 - val_loss: 0.1680 - val_accuracy: 0.7077\n",
      "Epoch 19/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1684 - accuracy: 0.7036\n",
      "Epoch 19: val_accuracy improved from 0.70940 to 0.72383, saving model to best_model.hdf5\n",
      "304/304 [==============================] - 68s 224ms/step - loss: 0.1685 - accuracy: 0.7035 - val_loss: 0.1646 - val_accuracy: 0.7238\n",
      "Epoch 20/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1664 - accuracy: 0.7092\n",
      "Epoch 20: val_accuracy did not improve from 0.72383\n",
      "304/304 [==============================] - 76s 250ms/step - loss: 0.1664 - accuracy: 0.7091 - val_loss: 0.1641 - val_accuracy: 0.7131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/400\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.1645 - accuracy: 0.7134\n",
      "Epoch 21: val_accuracy did not improve from 0.72383\n",
      "304/304 [==============================] - 70s 231ms/step - loss: 0.1645 - accuracy: 0.7134 - val_loss: 0.1620 - val_accuracy: 0.7181\n",
      "Epoch 22/400\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.1627 - accuracy: 0.7121\n",
      "Epoch 22: val_accuracy did not improve from 0.72383\n",
      "304/304 [==============================] - 68s 223ms/step - loss: 0.1627 - accuracy: 0.7121 - val_loss: 0.1633 - val_accuracy: 0.7143\n",
      "Epoch 23/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1616 - accuracy: 0.7161\n",
      "Epoch 23: val_accuracy improved from 0.72383 to 0.72630, saving model to best_model.hdf5\n",
      "304/304 [==============================] - 63s 207ms/step - loss: 0.1617 - accuracy: 0.7160 - val_loss: 0.1592 - val_accuracy: 0.7263\n",
      "Epoch 24/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1587 - accuracy: 0.7257\n",
      "Epoch 24: val_accuracy did not improve from 0.72630\n",
      "304/304 [==============================] - 65s 213ms/step - loss: 0.1587 - accuracy: 0.7256 - val_loss: 0.1606 - val_accuracy: 0.7222\n",
      "Epoch 25/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1571 - accuracy: 0.7279\n",
      "Epoch 25: val_accuracy did not improve from 0.72630\n",
      "304/304 [==============================] - 64s 210ms/step - loss: 0.1571 - accuracy: 0.7280 - val_loss: 0.1645 - val_accuracy: 0.7049\n",
      "Epoch 26/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1545 - accuracy: 0.7314\n",
      "Epoch 26: val_accuracy improved from 0.72630 to 0.73166, saving model to best_model.hdf5\n",
      "304/304 [==============================] - 69s 226ms/step - loss: 0.1544 - accuracy: 0.7315 - val_loss: 0.1562 - val_accuracy: 0.7317\n",
      "Epoch 27/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1537 - accuracy: 0.7349\n",
      "Epoch 27: val_accuracy did not improve from 0.73166\n",
      "304/304 [==============================] - 71s 232ms/step - loss: 0.1537 - accuracy: 0.7350 - val_loss: 0.1672 - val_accuracy: 0.7003\n",
      "Epoch 28/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1521 - accuracy: 0.7396\n",
      "Epoch 28: val_accuracy improved from 0.73166 to 0.74650, saving model to best_model.hdf5\n",
      "304/304 [==============================] - 76s 249ms/step - loss: 0.1521 - accuracy: 0.7395 - val_loss: 0.1497 - val_accuracy: 0.7465\n",
      "Epoch 29/400\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.1499 - accuracy: 0.7397\n",
      "Epoch 29: val_accuracy did not improve from 0.74650\n",
      "304/304 [==============================] - 71s 233ms/step - loss: 0.1499 - accuracy: 0.7397 - val_loss: 0.1522 - val_accuracy: 0.7407\n",
      "Epoch 30/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1471 - accuracy: 0.7489\n",
      "Epoch 30: val_accuracy did not improve from 0.74650\n",
      "304/304 [==============================] - 71s 233ms/step - loss: 0.1470 - accuracy: 0.7489 - val_loss: 0.1568 - val_accuracy: 0.7234\n",
      "Epoch 31/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1471 - accuracy: 0.7458\n",
      "Epoch 31: val_accuracy did not improve from 0.74650\n",
      "304/304 [==============================] - 72s 236ms/step - loss: 0.1471 - accuracy: 0.7458 - val_loss: 0.1588 - val_accuracy: 0.7209\n",
      "Epoch 32/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1457 - accuracy: 0.7519\n",
      "Epoch 32: val_accuracy improved from 0.74650 to 0.74815, saving model to best_model.hdf5\n",
      "304/304 [==============================] - 72s 237ms/step - loss: 0.1456 - accuracy: 0.7520 - val_loss: 0.1492 - val_accuracy: 0.7481\n",
      "Epoch 33/400\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.1435 - accuracy: 0.7574\n",
      "Epoch 33: val_accuracy did not improve from 0.74815\n",
      "304/304 [==============================] - 70s 231ms/step - loss: 0.1435 - accuracy: 0.7574 - val_loss: 0.1639 - val_accuracy: 0.7218\n",
      "Epoch 34/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1434 - accuracy: 0.7547\n",
      "Epoch 34: val_accuracy did not improve from 0.74815\n",
      "304/304 [==============================] - 70s 230ms/step - loss: 0.1434 - accuracy: 0.7549 - val_loss: 0.1541 - val_accuracy: 0.7387\n",
      "Epoch 35/400\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.1401 - accuracy: 0.7594\n",
      "Epoch 35: val_accuracy did not improve from 0.74815\n",
      "304/304 [==============================] - 65s 215ms/step - loss: 0.1401 - accuracy: 0.7594 - val_loss: 0.1447 - val_accuracy: 0.7453\n",
      "Epoch 36/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1394 - accuracy: 0.7643\n",
      "Epoch 36: val_accuracy did not improve from 0.74815\n",
      "304/304 [==============================] - 69s 225ms/step - loss: 0.1394 - accuracy: 0.7645 - val_loss: 0.1477 - val_accuracy: 0.7411\n",
      "Epoch 37/400\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.1389 - accuracy: 0.7677\n",
      "Epoch 37: val_accuracy improved from 0.74815 to 0.76298, saving model to best_model.hdf5\n",
      "304/304 [==============================] - 74s 244ms/step - loss: 0.1389 - accuracy: 0.7677 - val_loss: 0.1429 - val_accuracy: 0.7630\n",
      "Epoch 38/400\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.1345 - accuracy: 0.7736\n",
      "Epoch 38: val_accuracy did not improve from 0.76298\n",
      "304/304 [==============================] - 68s 224ms/step - loss: 0.1345 - accuracy: 0.7736 - val_loss: 0.1428 - val_accuracy: 0.7539\n",
      "Epoch 39/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1342 - accuracy: 0.7758\n",
      "Epoch 39: val_accuracy did not improve from 0.76298\n",
      "304/304 [==============================] - 72s 236ms/step - loss: 0.1342 - accuracy: 0.7759 - val_loss: 0.1467 - val_accuracy: 0.7494\n",
      "Epoch 40/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1324 - accuracy: 0.7741\n",
      "Epoch 40: val_accuracy improved from 0.76298 to 0.77040, saving model to best_model.hdf5\n",
      "304/304 [==============================] - 64s 212ms/step - loss: 0.1325 - accuracy: 0.7739 - val_loss: 0.1386 - val_accuracy: 0.7704\n",
      "Epoch 41/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1308 - accuracy: 0.7816\n",
      "Epoch 41: val_accuracy did not improve from 0.77040\n",
      "304/304 [==============================] - 64s 210ms/step - loss: 0.1308 - accuracy: 0.7817 - val_loss: 0.1408 - val_accuracy: 0.7646\n",
      "Epoch 42/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1305 - accuracy: 0.7828\n",
      "Epoch 42: val_accuracy did not improve from 0.77040\n",
      "304/304 [==============================] - 65s 212ms/step - loss: 0.1304 - accuracy: 0.7828 - val_loss: 0.1495 - val_accuracy: 0.7329\n",
      "Epoch 43/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1281 - accuracy: 0.7862\n",
      "Epoch 43: val_accuracy did not improve from 0.77040\n",
      "304/304 [==============================] - 70s 230ms/step - loss: 0.1281 - accuracy: 0.7861 - val_loss: 0.1381 - val_accuracy: 0.7622\n",
      "Epoch 44/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1280 - accuracy: 0.7879\n",
      "Epoch 44: val_accuracy improved from 0.77040 to 0.77329, saving model to best_model.hdf5\n",
      "304/304 [==============================] - 75s 248ms/step - loss: 0.1280 - accuracy: 0.7879 - val_loss: 0.1354 - val_accuracy: 0.7733\n",
      "Epoch 45/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1257 - accuracy: 0.7908\n",
      "Epoch 45: val_accuracy did not improve from 0.77329\n",
      "304/304 [==============================] - 67s 220ms/step - loss: 0.1257 - accuracy: 0.7908 - val_loss: 0.1361 - val_accuracy: 0.7630\n",
      "Epoch 46/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1240 - accuracy: 0.7937\n",
      "Epoch 46: val_accuracy did not improve from 0.77329\n",
      "304/304 [==============================] - 72s 236ms/step - loss: 0.1240 - accuracy: 0.7937 - val_loss: 0.1362 - val_accuracy: 0.7638\n",
      "Epoch 47/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1235 - accuracy: 0.7957\n",
      "Epoch 47: val_accuracy improved from 0.77329 to 0.77865, saving model to best_model.hdf5\n",
      "304/304 [==============================] - 69s 229ms/step - loss: 0.1235 - accuracy: 0.7956 - val_loss: 0.1338 - val_accuracy: 0.7786\n",
      "Epoch 48/400\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.1217 - accuracy: 0.7990\n",
      "Epoch 48: val_accuracy did not improve from 0.77865\n",
      "304/304 [==============================] - 69s 229ms/step - loss: 0.1217 - accuracy: 0.7990 - val_loss: 0.1342 - val_accuracy: 0.7754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1201 - accuracy: 0.8005\n",
      "Epoch 49: val_accuracy did not improve from 0.77865\n",
      "304/304 [==============================] - 70s 229ms/step - loss: 0.1201 - accuracy: 0.8006 - val_loss: 0.1377 - val_accuracy: 0.7543\n",
      "Epoch 50/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1190 - accuracy: 0.8011\n",
      "Epoch 50: val_accuracy did not improve from 0.77865\n",
      "304/304 [==============================] - 71s 232ms/step - loss: 0.1190 - accuracy: 0.8009 - val_loss: 0.1353 - val_accuracy: 0.7663\n",
      "Epoch 51/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1170 - accuracy: 0.8085\n",
      "Epoch 51: val_accuracy did not improve from 0.77865\n",
      "304/304 [==============================] - 69s 225ms/step - loss: 0.1169 - accuracy: 0.8086 - val_loss: 0.1361 - val_accuracy: 0.7700\n",
      "Epoch 52/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1162 - accuracy: 0.8102\n",
      "Epoch 52: val_accuracy improved from 0.77865 to 0.77906, saving model to best_model.hdf5\n",
      "304/304 [==============================] - 69s 226ms/step - loss: 0.1162 - accuracy: 0.8102 - val_loss: 0.1338 - val_accuracy: 0.7791\n",
      "Epoch 53/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1137 - accuracy: 0.8135\n",
      "Epoch 53: val_accuracy improved from 0.77906 to 0.78236, saving model to best_model.hdf5\n",
      "304/304 [==============================] - 69s 228ms/step - loss: 0.1136 - accuracy: 0.8136 - val_loss: 0.1306 - val_accuracy: 0.7824\n",
      "Epoch 54/400\n",
      "304/304 [==============================] - ETA: 0s - loss: 0.1131 - accuracy: 0.8152\n",
      "Epoch 54: val_accuracy did not improve from 0.78236\n",
      "304/304 [==============================] - 93s 306ms/step - loss: 0.1131 - accuracy: 0.8152 - val_loss: 0.1336 - val_accuracy: 0.7700\n",
      "Epoch 55/400\n",
      "303/304 [============================>.] - ETA: 0s - loss: 0.1122 - accuracy: 0.8160\n",
      "Epoch 55: val_accuracy did not improve from 0.78236\n",
      "304/304 [==============================] - 82s 270ms/step - loss: 0.1122 - accuracy: 0.8161 - val_loss: 0.1531 - val_accuracy: 0.7407\n",
      "Epoch 56/400\n",
      " 92/304 [========>.....................] - ETA: 52s - loss: 0.1117 - accuracy: 0.8190"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras.layers import Dense,Activation,Dropout\n",
    "DATA_PATH = \"E:\\Research\\ML - Machine Learning\\Music Genre Classification\\Final Data\\mfcc_40.json\"\n",
    "\n",
    "\n",
    "def load_data(data_path):\n",
    "    \"\"\"Loads training dataset from json file.\n",
    "\n",
    "        :param data_path (str): Path to json file containing data\n",
    "        :return X (ndarray): Inputs\n",
    "        :return y (ndarray): Targets\n",
    "    \"\"\"\n",
    "\n",
    "    with open(data_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    \"\"\"Plots accuracy/loss for training/validation set as a function of the epochs\n",
    "\n",
    "        :param history: Training history of model\n",
    "        :return:\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axs = plt.subplots(2)\n",
    "\n",
    "    # create accuracy sublpot\n",
    "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
    "    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
    "    axs[0].set_ylabel(\"Accuracy\")\n",
    "    axs[0].legend(loc=\"lower right\")\n",
    "    axs[1].set_xlabel(\"Epoch\")\n",
    "    axs[0].set_title(\"Accuracy evaluation\")\n",
    "\n",
    "    # create error sublpot\n",
    "    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
    "    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n",
    "    axs[1].set_ylabel(\"Error\")\n",
    "    axs[1].set_xlabel(\"Epoch\")\n",
    "    axs[1].legend(loc=\"upper right\")\n",
    "    axs[1].set_title(\"Error evaluation\")\n",
    "    \n",
    "    plt.subplots_adjust(hspace=0.8)\n",
    "    \n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def prepare_datasets(test_size, validation_size):\n",
    "    \"\"\"Loads data and splits it into train, validation and test sets.\n",
    "\n",
    "    :param test_size (float): Value in [0, 1] indicating percentage of data set to allocate to test split\n",
    "    :param validation_size (float): Value in [0, 1] indicating percentage of train set to allocate to validation split\n",
    "\n",
    "    :return X_train (ndarray): Input training set\n",
    "    :return X_validation (ndarray): Input validation set\n",
    "    :return X_test (ndarray): Input test set\n",
    "    :return y_train (ndarray): Target training set\n",
    "    :return y_validation (ndarray): Target validation set\n",
    "    :return y_test (ndarray): Target test set\n",
    "    \"\"\"\n",
    "\n",
    "    # load data\n",
    "    X, y = load_data(DATA_PATH)\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)\n",
    "    \n",
    "    \n",
    "\n",
    "    # create train, validation and test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
    "\n",
    "    # add an axis to input sets\n",
    "    X_train = X_train[..., np.newaxis]\n",
    "    X_validation = X_validation[..., np.newaxis]\n",
    "    X_test = X_test[..., np.newaxis]\n",
    "    \n",
    "#     # Convert integer labels to one-hot encoding\n",
    "    y_train = to_categorical(y_train, num_classes=8)\n",
    "    y_validation = to_categorical(y_validation, num_classes=8)\n",
    "\n",
    "    return X_train, X_validation, X_test, y_train, y_validation, y_test\n",
    "\n",
    "\n",
    "def build_model(input_shape):\n",
    "    \"\"\"Generates CNN model\n",
    "\n",
    "    :param input_shape (tuple): Shape of input set\n",
    "    :return model: CNN model\n",
    "    \"\"\"\n",
    "\n",
    "    # build network topology\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # 1st conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPooling2D(2, padding='valid'))\n",
    "    #model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # 2nd conv layer\n",
    "    model.add(keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D(2, padding='valid'))\n",
    "    model.add(Dropout(0.3))\n",
    "    #model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # 3rd conv layer\n",
    "    model.add(keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D(1, padding='valid'))\n",
    "    model.add(Dropout(0.3))\n",
    "    #model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # output layer\n",
    "    model.add(keras.layers.GlobalAveragePooling2D())\n",
    "    model.add(keras.layers.Dense(512, activation='relu'))\n",
    "    model.add(keras.layers.Dense(8, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict(model, X, y):\n",
    "    \"\"\"Predict a single sample using the trained model\n",
    "\n",
    "    :param model: Trained classifier\n",
    "    :param X: Input data\n",
    "    :param y (int): Target\n",
    "    \"\"\"\n",
    "\n",
    "    # add a dimension to input data for sample - model.predict() expects a 4d array in this case\n",
    "    X = X[np.newaxis, ...] # array shape (1, 130, 13, 1)\n",
    "\n",
    "    # perform prediction\n",
    "    prediction = model.predict(X)\n",
    "\n",
    "    # get index with max value\n",
    "    predicted_index = np.argmax(prediction, axis=1)\n",
    "\n",
    "    \n",
    "    print(\"Target: {}, Predicted label: {}\".format(y, predicted_index))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # get train, validation, test splits\n",
    "    X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_datasets(0.25, 0.2)\n",
    "\n",
    "    # create network\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
    "    model = build_model(input_shape)\n",
    "\n",
    "    # compile model\n",
    "    optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimiser,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "   \n",
    "    earlystop = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=10,min_delta=0.0001)\n",
    "    modelcheck = ModelCheckpoint('best_model.hdf5',monitor='val_accuracy',verbose=1,save_best_only=True,mode='max')\n",
    "    \n",
    "    # train model\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=32, epochs=400, callbacks=[modelcheck])\n",
    "\n",
    "    # plot accuracy/error for training and validation\n",
    "    plot_history(history)\n",
    "    \n",
    "    y_test = to_categorical(y_test, num_classes=8)\n",
    "    \n",
    "    # evaluate model on test set\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "    print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "    # pick a sample to predict from the test set\n",
    "    X_to_predict = X_test[100]\n",
    "    y_to_predict = y_test[100]\n",
    "\n",
    "    # predict sample\n",
    "    predict(model, X_to_predict, y_to_predict)\n",
    "    \n",
    "    genre_names = [\n",
    "    \"Adhunik\", \"Folk\", \"Hiphop\", \"Indie\", \n",
    "    \"Islamic\", \"Metal\", \"Pop\", \"Rock\"\n",
    "    ]\n",
    "    \n",
    "    # Generate predictions for the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "    \n",
    "    # Generate classification report\n",
    "    print(classification_report(y_test, y_pred_classes))\n",
    "\n",
    "   # Generate confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred_classes)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\", xticklabels=genre_names, yticklabels=genre_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()  # Show the plot\n",
    "\n",
    "    # Save the plot after showing it\n",
    "    plt.savefig(\"sample_plot.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8527f673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
